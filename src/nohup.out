The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/model_checkpointing/checkpoint_handler.py:30: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  import torch.distributed._shard.checkpoint as dist_cp
/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/model_checkpointing/checkpoint_handler.py:30: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  import torch.distributed._shard.checkpoint as dist_cp
/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/model_checkpointing/checkpoint_handler.py:30: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  import torch.distributed._shard.checkpoint as dist_cp
/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/model_checkpointing/checkpoint_handler.py:30: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  import torch.distributed._shard.checkpoint as dist_cp
/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/model_checkpointing/checkpoint_handler.py:30: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  import torch.distributed._shard.checkpoint as dist_cp
/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/model_checkpointing/checkpoint_handler.py:30: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  import torch.distributed._shard.checkpoint as dist_cp
/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/model_checkpointing/checkpoint_handler.py:30: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  import torch.distributed._shard.checkpoint as dist_cp
--> Training Set Length = 200
--> Validation Set Length = 100
==============original test================
WARNING 01-13 16:48:54 config.py:1865] Casting torch.bfloat16 to torch.float16.
WARNING 01-13 16:48:54 config.py:1865] Casting torch.bfloat16 to torch.float16.
WARNING 01-13 16:48:54 config.py:1865] Casting torch.bfloat16 to torch.float16.
WARNING 01-13 16:48:54 config.py:1865] Casting torch.bfloat16 to torch.float16.
WARNING 01-13 16:48:54 config.py:1865] Casting torch.bfloat16 to torch.float16.
WARNING 01-13 16:48:54 config.py:1865] Casting torch.bfloat16 to torch.float16.
WARNING 01-13 16:48:54 config.py:1865] Casting torch.bfloat16 to torch.float16.
INFO 01-13 16:48:58 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.
WARNING 01-13 16:48:58 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-13 16:48:58 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.
WARNING 01-13 16:48:58 config.py:503] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 01-13 16:48:58 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='../../meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='../../meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=../../meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-13 16:48:58 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.
WARNING 01-13 16:48:58 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-13 16:48:58 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.
WARNING 01-13 16:48:58 config.py:503] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 01-13 16:48:58 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='../../meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='../../meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=../../meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-13 16:48:58 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.
WARNING 01-13 16:48:58 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-13 16:48:58 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.
WARNING 01-13 16:48:58 config.py:503] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 01-13 16:48:58 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='../../meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='../../meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=../../meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-13 16:48:58 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.
WARNING 01-13 16:48:58 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-13 16:48:58 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.
WARNING 01-13 16:48:58 config.py:503] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 01-13 16:48:58 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='../../meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='../../meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=../../meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-13 16:48:58 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.
WARNING 01-13 16:48:58 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-13 16:48:58 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.
WARNING 01-13 16:48:58 config.py:503] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 01-13 16:48:58 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='../../meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='../../meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=../../meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-13 16:48:58 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.
WARNING 01-13 16:48:58 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-13 16:48:58 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.
WARNING 01-13 16:48:58 config.py:503] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 01-13 16:48:58 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='../../meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='../../meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=../../meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-13 16:48:58 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.
WARNING 01-13 16:48:58 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-13 16:48:58 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.
WARNING 01-13 16:48:58 config.py:503] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 01-13 16:48:58 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='../../meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='../../meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=../../meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-13 16:48:58 selector.py:135] Using Flash Attention backend.
INFO 01-13 16:48:58 selector.py:135] Using Flash Attention backend.
INFO 01-13 16:48:58 selector.py:135] Using Flash Attention backend.
INFO 01-13 16:48:58 selector.py:135] Using Flash Attention backend.
INFO 01-13 16:48:58 selector.py:135] Using Flash Attention backend.
INFO 01-13 16:48:58 selector.py:135] Using Flash Attention backend.
INFO 01-13 16:48:58 selector.py:135] Using Flash Attention backend.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 237, in <module>
[rank2]:     fire.Fire(main)
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 143, in Fire
[rank2]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 477, in _Fire
[rank2]:     component, remaining_args = _CallAndUpdateTrace(
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
[rank2]:     component = fn(*varargs, **kwargs)
[rank2]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 152, in main
[rank2]:     test_vllm(train_config, dataset_test, tokenizer, wandb_run, original=True)
[rank2]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/utils/train_utils_uncertainty.py", line 505, in test_vllm
[rank2]:     llm = LLM(
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/utils.py", line 1028, in inner
[rank2]:     return fn(*args, **kwargs)
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 210, in __init__
[rank2]:     self.llm_engine = self.engine_class.from_engine_args(
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 585, in from_engine_args
[rank2]:     engine = cls(
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 347, in __init__
[rank2]:     self.model_executor = executor_class(vllm_config=vllm_config, )
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/executor_base.py", line 36, in __init__
[rank2]:     self._init_executor()
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/gpu_executor.py", line 39, in _init_executor
[rank2]:     self.driver_worker.init_device()
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 145, in init_device
[rank2]:     init_worker_distributed_environment(self.parallel_config, self.rank,
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 462, in init_worker_distributed_environment
[rank2]:     ensure_model_parallel_initialized(parallel_config.tensor_parallel_size,
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1105, in ensure_model_parallel_initialized
[rank2]:     initialize_model_parallel(tensor_model_parallel_size,
[rank2]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1051, in initialize_model_parallel
[rank2]:     raise RuntimeError(
[rank2]: RuntimeError: world_size (7) is not equal to tensor_model_parallel_size (1) x pipeline_model_parallel_size (1)
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 237, in <module>
[rank4]:     fire.Fire(main)
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 143, in Fire
[rank4]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 477, in _Fire
[rank4]:     component, remaining_args = _CallAndUpdateTrace(
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
[rank4]:     component = fn(*varargs, **kwargs)
[rank4]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 152, in main
[rank4]:     test_vllm(train_config, dataset_test, tokenizer, wandb_run, original=True)
[rank4]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/utils/train_utils_uncertainty.py", line 505, in test_vllm
[rank4]:     llm = LLM(
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/utils.py", line 1028, in inner
[rank4]:     return fn(*args, **kwargs)
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 210, in __init__
[rank4]:     self.llm_engine = self.engine_class.from_engine_args(
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 585, in from_engine_args
[rank4]:     engine = cls(
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 347, in __init__
[rank4]:     self.model_executor = executor_class(vllm_config=vllm_config, )
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/executor_base.py", line 36, in __init__
[rank4]:     self._init_executor()
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/gpu_executor.py", line 39, in _init_executor
[rank4]:     self.driver_worker.init_device()
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 145, in init_device
[rank4]:     init_worker_distributed_environment(self.parallel_config, self.rank,
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 462, in init_worker_distributed_environment
[rank4]:     ensure_model_parallel_initialized(parallel_config.tensor_parallel_size,
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1105, in ensure_model_parallel_initialized
[rank4]:     initialize_model_parallel(tensor_model_parallel_size,
[rank4]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1051, in initialize_model_parallel
[rank4]:     raise RuntimeError(
[rank4]: RuntimeError: world_size (7) is not equal to tensor_model_parallel_size (1) x pipeline_model_parallel_size (1)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 237, in <module>
[rank1]:     fire.Fire(main)
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 143, in Fire
[rank1]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 477, in _Fire
[rank1]:     component, remaining_args = _CallAndUpdateTrace(
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
[rank1]:     component = fn(*varargs, **kwargs)
[rank1]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 152, in main
[rank1]:     test_vllm(train_config, dataset_test, tokenizer, wandb_run, original=True)
[rank1]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/utils/train_utils_uncertainty.py", line 505, in test_vllm
[rank1]:     llm = LLM(
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/utils.py", line 1028, in inner
[rank1]:     return fn(*args, **kwargs)
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 210, in __init__
[rank1]:     self.llm_engine = self.engine_class.from_engine_args(
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 585, in from_engine_args
[rank1]:     engine = cls(
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 347, in __init__
[rank1]:     self.model_executor = executor_class(vllm_config=vllm_config, )
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/executor_base.py", line 36, in __init__
[rank1]:     self._init_executor()
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/gpu_executor.py", line 39, in _init_executor
[rank1]:     self.driver_worker.init_device()
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 145, in init_device
[rank1]:     init_worker_distributed_environment(self.parallel_config, self.rank,
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 462, in init_worker_distributed_environment
[rank1]:     ensure_model_parallel_initialized(parallel_config.tensor_parallel_size,
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1105, in ensure_model_parallel_initialized
[rank1]:     initialize_model_parallel(tensor_model_parallel_size,
[rank1]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1051, in initialize_model_parallel
[rank1]:     raise RuntimeError(
[rank1]: RuntimeError: world_size (7) is not equal to tensor_model_parallel_size (1) x pipeline_model_parallel_size (1)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 237, in <module>
[rank0]:     fire.Fire(main)
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 143, in Fire
[rank0]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 477, in _Fire
[rank0]:     component, remaining_args = _CallAndUpdateTrace(
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
[rank0]:     component = fn(*varargs, **kwargs)
[rank0]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 152, in main
[rank0]:     test_vllm(train_config, dataset_test, tokenizer, wandb_run, original=True)
[rank0]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/utils/train_utils_uncertainty.py", line 505, in test_vllm
[rank0]:     llm = LLM(
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/utils.py", line 1028, in inner
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 210, in __init__
[rank0]:     self.llm_engine = self.engine_class.from_engine_args(
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 585, in from_engine_args
[rank0]:     engine = cls(
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 347, in __init__
[rank0]:     self.model_executor = executor_class(vllm_config=vllm_config, )
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/executor_base.py", line 36, in __init__
[rank0]:     self._init_executor()
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/gpu_executor.py", line 39, in _init_executor
[rank0]:     self.driver_worker.init_device()
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 145, in init_device
[rank0]:     init_worker_distributed_environment(self.parallel_config, self.rank,
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 462, in init_worker_distributed_environment
[rank0]:     ensure_model_parallel_initialized(parallel_config.tensor_parallel_size,
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1105, in ensure_model_parallel_initialized
[rank0]:     initialize_model_parallel(tensor_model_parallel_size,
[rank0]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1051, in initialize_model_parallel
[rank0]:     raise RuntimeError(
[rank0]: RuntimeError: world_size (7) is not equal to tensor_model_parallel_size (1) x pipeline_model_parallel_size (1)
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 237, in <module>
[rank5]:     fire.Fire(main)
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 143, in Fire
[rank5]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 477, in _Fire
[rank5]:     component, remaining_args = _CallAndUpdateTrace(
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
[rank5]:     component = fn(*varargs, **kwargs)
[rank5]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 152, in main
[rank5]:     test_vllm(train_config, dataset_test, tokenizer, wandb_run, original=True)
[rank5]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/utils/train_utils_uncertainty.py", line 505, in test_vllm
[rank5]:     llm = LLM(
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/utils.py", line 1028, in inner
[rank5]:     return fn(*args, **kwargs)
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 210, in __init__
[rank5]:     self.llm_engine = self.engine_class.from_engine_args(
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 585, in from_engine_args
[rank5]:     engine = cls(
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 347, in __init__
[rank5]:     self.model_executor = executor_class(vllm_config=vllm_config, )
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/executor_base.py", line 36, in __init__
[rank5]:     self._init_executor()
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/gpu_executor.py", line 39, in _init_executor
[rank5]:     self.driver_worker.init_device()
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 145, in init_device
[rank5]:     init_worker_distributed_environment(self.parallel_config, self.rank,
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 462, in init_worker_distributed_environment
[rank5]:     ensure_model_parallel_initialized(parallel_config.tensor_parallel_size,
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1105, in ensure_model_parallel_initialized
[rank5]:     initialize_model_parallel(tensor_model_parallel_size,
[rank5]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1051, in initialize_model_parallel
[rank5]:     raise RuntimeError(
[rank5]: RuntimeError: world_size (7) is not equal to tensor_model_parallel_size (1) x pipeline_model_parallel_size (1)
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 237, in <module>
[rank3]:     fire.Fire(main)
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 143, in Fire
[rank3]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 477, in _Fire
[rank3]:     component, remaining_args = _CallAndUpdateTrace(
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
[rank3]:     component = fn(*varargs, **kwargs)
[rank3]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 152, in main
[rank3]:     test_vllm(train_config, dataset_test, tokenizer, wandb_run, original=True)
[rank3]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/utils/train_utils_uncertainty.py", line 505, in test_vllm
[rank3]:     llm = LLM(
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/utils.py", line 1028, in inner
[rank3]:     return fn(*args, **kwargs)
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 210, in __init__
[rank3]:     self.llm_engine = self.engine_class.from_engine_args(
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 585, in from_engine_args
[rank3]:     engine = cls(
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 347, in __init__
[rank3]:     self.model_executor = executor_class(vllm_config=vllm_config, )
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/executor_base.py", line 36, in __init__
[rank3]:     self._init_executor()
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/gpu_executor.py", line 39, in _init_executor
[rank3]:     self.driver_worker.init_device()
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 145, in init_device
[rank3]:     init_worker_distributed_environment(self.parallel_config, self.rank,
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 462, in init_worker_distributed_environment
[rank3]:     ensure_model_parallel_initialized(parallel_config.tensor_parallel_size,
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1105, in ensure_model_parallel_initialized
[rank3]:     initialize_model_parallel(tensor_model_parallel_size,
[rank3]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1051, in initialize_model_parallel
[rank3]:     raise RuntimeError(
[rank3]: RuntimeError: world_size (7) is not equal to tensor_model_parallel_size (1) x pipeline_model_parallel_size (1)
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 237, in <module>
[rank6]:     fire.Fire(main)
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 143, in Fire
[rank6]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 477, in _Fire
[rank6]:     component, remaining_args = _CallAndUpdateTrace(
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
[rank6]:     component = fn(*varargs, **kwargs)
[rank6]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/uncertainty_sft.py", line 152, in main
[rank6]:     test_vllm(train_config, dataset_test, tokenizer, wandb_run, original=True)
[rank6]:   File "/home/tri/zhiyuan/yibo/Uncertainty_ft/src/llama_recipes/utils/train_utils_uncertainty.py", line 505, in test_vllm
[rank6]:     llm = LLM(
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/utils.py", line 1028, in inner
[rank6]:     return fn(*args, **kwargs)
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/entrypoints/llm.py", line 210, in __init__
[rank6]:     self.llm_engine = self.engine_class.from_engine_args(
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 585, in from_engine_args
[rank6]:     engine = cls(
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/engine/llm_engine.py", line 347, in __init__
[rank6]:     self.model_executor = executor_class(vllm_config=vllm_config, )
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/executor_base.py", line 36, in __init__
[rank6]:     self._init_executor()
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/executor/gpu_executor.py", line 39, in _init_executor
[rank6]:     self.driver_worker.init_device()
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 145, in init_device
[rank6]:     init_worker_distributed_environment(self.parallel_config, self.rank,
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/worker/worker.py", line 462, in init_worker_distributed_environment
[rank6]:     ensure_model_parallel_initialized(parallel_config.tensor_parallel_size,
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1105, in ensure_model_parallel_initialized
[rank6]:     initialize_model_parallel(tensor_model_parallel_size,
[rank6]:   File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/vllm/distributed/parallel_state.py", line 1051, in initialize_model_parallel
[rank6]:     raise RuntimeError(
[rank6]: RuntimeError: world_size (7) is not equal to tensor_model_parallel_size (1) x pipeline_model_parallel_size (1)
[rank0]:[W113 16:49:00.192952044 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W0113 16:49:00.996858 2765356 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2765500 closing signal SIGTERM
W0113 16:49:00.997412 2765356 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2765501 closing signal SIGTERM
W0113 16:49:00.997567 2765356 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2765502 closing signal SIGTERM
W0113 16:49:00.997717 2765356 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2765504 closing signal SIGTERM
W0113 16:49:00.997862 2765356 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2765506 closing signal SIGTERM
W0113 16:49:00.997992 2765356 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2765507 closing signal SIGTERM
E0113 16:49:01.781936 2765356 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 4 (pid: 2765505) of binary: /home/tri/miniconda3/envs/uncertainty2/bin/python
Traceback (most recent call last):
  File "/home/tri/miniconda3/envs/uncertainty2/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1159, in launch_command
    multi_gpu_launcher(args)
  File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/accelerate/commands/launch.py", line 793, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/tri/miniconda3/envs/uncertainty2/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
uncertainty_sft.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-13_16:49:00
  host      : gpuserver18
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 2765505)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
